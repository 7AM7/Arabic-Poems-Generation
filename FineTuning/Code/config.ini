[model1]
model_name = aubmindlab/bert-base-arabert
batch_size = 32
epochs = 4
lr = 5e-05
adam_epsilon = 1e-08

[model2]
model_name = asafaya/bert-base-arabic
batch_size = 32
epochs = 4
lr = 5e-05
adam_epsilon = 1e-08

[model3]
model_name = akhooli/gpt2-small-arabic
warmup_steps = 100.0
epochs = 5
lr = 0.0005
adam_epsilon = 1e-08
sample_every = 100
batch_size = 2

